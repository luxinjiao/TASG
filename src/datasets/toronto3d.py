import os
import sys
import torch
import shutil
import logging
import os.path as osp
from plyfile import PlyData
from typing import List
from torch_geometric.nn.pool.consecutive import consecutive_cluster
from torch_geometric.data import extract_zip

from src.datasets import BaseDataset
from src.data import Data, InstanceData
from src.datasets.toronto3d_config import *

DIR = os.path.dirname(os.path.realpath(__file__))
log = logging.getLogger(__name__)

# å¤šè¿›ç¨‹å…±äº«ç­–ç•¥
import torch.multiprocessing
torch.multiprocessing.set_sharing_strategy('file_system')

__all__ = ['Toronto3D', 'MiniToronto3D']

########################################################################
#                                Utils                                #
########################################################################


def read_toronto3d_ply(
        filepath, 
        xyz=True, 
        intensity=True, 
        semantic=True,
        instance=False,  
        remap=False,
        rgb=True  # æ–°å¢žRGBå¤„ç†å¼€å…³
    ):
    data = Data()
    
    with open(filepath, "rb") as f:
        ply = PlyData.read(f)
        vertex = ply['vertex']
        
        # ç»Ÿä¸€ä½¿ç”¨torch.FloatTensorç±»åž‹åŒ–å¤„ç†
        def safe_tensor(arr, dtype=np.float32):
            return torch.FloatTensor(np.ascontiguousarray(arr.astype(dtype)))
        
        # 1. åæ ‡å¤„ç†ï¼ˆä¿æŒåŽŸæ ·ï¼‰
        if xyz:
            pos = torch.stack([
                safe_tensor(vertex['x']),
                safe_tensor(vertex['y']),
                safe_tensor(vertex['z'])
            ], dim=-1)
            pos_offset = pos[0]
            data.pos = pos - pos_offset
            data.pos_offset = pos_offset
            
        # 2. RGBå¤„ç†ï¼ˆå…³é”®æ–°å¢žï¼‰
        if rgb:
            # ç¡®ä¿PLYæ–‡ä»¶åŒ…å«é¢œè‰²å±žæ€§[ç½‘é¡µ1]
            
            data.rgb = torch.stack([
                safe_tensor(vertex['red'], dtype=np.uint8),
                safe_tensor(vertex['green'], dtype=np.uint8),
                safe_tensor(vertex['blue'], dtype=np.uint8)
            ], dim=-1).float() / 255.0  # å½’ä¸€åŒ–åˆ°[0,1]

        # 3. è¯­ä¹‰æ ‡ç­¾å¤„ç†ï¼ˆä¿æŒåŽŸæœ‰é€»è¾‘ï¼‰
        if semantic:
            labels = vertex['scalar_Label']
            if labels.dtype != np.int_:
                labels = labels.astype(np.int64)
            data.y = torch.LongTensor(np.ascontiguousarray(labels))
        
        # 4. è¿‡æ»¤æ— æ•ˆç‚¹ï¼ˆä¿æŒåŽŸé€»è¾‘ï¼‰
        if semantic and remap:
            mask = (data.y != TORONTO3D_IGNORE_ID).squeeze()
            filtered_data = Data()
            for key in data.keys:
                tensor = data[key]
                if tensor.size(0) == data.num_nodes:  
                    filtered_data[key] = tensor[mask]
            data = filtered_data
    
    return data

########################################################################
#                              Toronto3D                              #
########################################################################

class Toronto3D(BaseDataset):
    """Toronto3Dæ•°æ®é›† (åŸºäºŽDALESç»“æž„è°ƒæ•´) ðŸŒŸ å…³é”®ç±»ç»“æž„ä¿æŒä¸€è‡´"""

    # æ•°æ®é›†å…ƒä¿¡æ¯
    @property
    def class_names(self) -> List[str]:
        return CLASS_NAMES

    @property
    def num_classes(self) -> int:
        return TORONTO3D_NUM_CLASSES

    @property 
    def stuff_classes(self) -> List[int]:
        return STUFF_CLASSES

    @property
    def class_colors(self) -> List[List[int]]:
        return CLASS_COLORS.tolist()

    # æ–‡ä»¶è·¯å¾„é…ç½®
    _zip_name = "Toronto_3D.zip"
    _unzip_name = "Toronto_3D"  # ðŸŒŸ æ˜Žç¡®è§£åŽ‹ç›®å½•å

    @property
    def raw_dir(self) -> str:
        return osp.join(self.root, "raw", self._unzip_name)

    # æ•°æ®é›†åˆ’åˆ†
    @property
    def all_base_cloud_ids(self) -> dict:
        return {
            'train': ['L001', 'L003'],
            'val': ['L004'],
            'test': ['L002']
        }

    # æ ¸å¿ƒæ–¹æ³• ðŸŒŸ ä¿æŒä¸ŽDALESç›¸åŒçš„æ–¹æ³•ç»“æž„
    def download_dataset(self) -> None:
        zip_path = osp.join(self.root, self._zip_name)
        
        # 1. æ£€æŸ¥åŽŸå§‹ZIPå­˜åœ¨æ€§
        if not osp.exists(zip_path):
            raise FileNotFoundError(f"è¯·å°† {self._zip_name} æ”¾å…¥ {self.root}")

        # 2. æ£€æŸ¥æ˜¯å¦å·²å®Œæˆè§£åŽ‹
        required_files = {'L001.ply', 'L002.ply', 'L003.ply', 'L004.ply'}
        existing_files = set(os.listdir(self.raw_dir)) if osp.exists(self.raw_dir) else set()
        
        # ðŸŒŸ å…³é”®ä¿®æ”¹ï¼šå¦‚æžœæ–‡ä»¶å·²å­˜åœ¨åˆ™è·³è¿‡è§£åŽ‹
        if required_files.issubset(existing_files):
            log.info(f"æ£€æµ‹åˆ° {self.raw_dir} å·²åŒ…å«å…¨éƒ¨æ–‡ä»¶ï¼Œè·³è¿‡è§£åŽ‹")
            return

        # 3. æ‰§è¡Œè§£åŽ‹æ“ä½œ
        log.info(f"å¼€å§‹è§£åŽ‹ {self._zip_name}...")
        tmp_dir = osp.join(self.root, "raw", "tmp_extract")
        os.makedirs(tmp_dir, exist_ok=True)
        
        # ðŸŒŸ å®‰å…¨è§£åŽ‹åˆ°ä¸´æ—¶ç›®å½•
        extract_zip(zip_path, tmp_dir)
        
        # 4. å¤„ç†åµŒå¥—ç›®å½•ç»“æž„
        actual_files = []
        for root, _, files in os.walk(tmp_dir):
            if any(f in required_files for f in files):
                actual_files.extend(osp.join(root, f) for f in files if f in required_files)
        
        # 5. ç§»åŠ¨æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
        os.makedirs(self.raw_dir, exist_ok=True)
        for src in actual_files:
            dst = osp.join(self.raw_dir, osp.basename(src))
            if not osp.exists(dst):  # ðŸŒŸ é¿å…é‡å¤ç§»åŠ¨
                shutil.move(src, dst)
        
        # 6. æ¸…ç†ä¸´æ—¶ç›®å½•
        shutil.rmtree(tmp_dir)
        
        # 7. æœ€ç»ˆéªŒè¯
        existing = set(os.listdir(self.raw_dir))
        if not required_files.issubset(existing):
            missing = required_files - existing
            raise RuntimeError(f"è§£åŽ‹å¤±è´¥ï¼ç¼ºå¤±æ–‡ä»¶: {missing}")

    def read_single_raw_cloud(self, raw_cloud_path: str) -> Data:  # ðŸŒŸ å¿…é¡»å®žçŽ°
        """è¯»å–å•ä¸ªåŽŸå§‹æ–‡ä»¶"""
        return read_toronto3d_ply(
            raw_cloud_path,
            intensity=True,
            semantic=True,
            remap=True,
            rgb=True  # å¼ºåˆ¶å¯ç”¨RGB
        )

    # è·¯å¾„è½¬æ¢æ–¹æ³•
    def id_to_relative_raw_path(self, id: str) -> str:
        """IDè½¬ç›¸å¯¹è·¯å¾„"""
        return osp.join(self._unzip_name, f"{id}.ply")

    def processed_to_raw_path(self, processed_path: str) -> str:
        """å¤„ç†è·¯å¾„è½¬åŽŸå§‹è·¯å¾„"""
        parts = processed_path.split(os.sep)
        cloud_id = osp.splitext(parts[-1])[0].split('_')[0]
        return osp.join(self.raw_dir, f"{cloud_id}.ply")

    # å¤„ç†å¢žå¼º
    def _process_single_cloud(self, p: str) -> None:
        """æ·»åŠ RGBç»´åº¦æ ¡éªŒ"""
        data = self.read_single_raw_cloud(self.processed_to_raw_path(p))
        assert hasattr(data, 'rgb'), "RGBé€šé“æœªæ­£ç¡®åŠ è½½"
        super()._process_single_cloud(p)

########################################################################
#                            MiniToronto3D                            #
########################################################################

class MiniToronto3D(Toronto3D):
    """è¿·ä½ ç‰ˆæ•°æ®é›† ðŸŒŸ ç»§æ‰¿ç»“æž„ä¿æŒä¸€è‡´"""
    _NUM_MINI = 1

    @property
    def all_cloud_ids(self) -> dict:
        return {k: v[:self._NUM_MINI] for k, v in super().all_cloud_ids.items()}

    @property
    def data_subdir_name(self) -> str:
        return "toronto3d"

    # ðŸŒŸ ä¿æŒä¸ŽMiniDALESç›¸åŒçš„é‡å†™æ–¹æ³•
    def process(self) -> None:
        self._pre_filter = None
        self._pre_transform = None
        super().process()

    def download(self) -> None:
        super().download()

